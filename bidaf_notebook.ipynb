{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO: ADD DROPOUT\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=5)\n",
    "        self.fc = nn.Linear(100, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #conv1d wants (N, C, L)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        #print(x.shape)\n",
    "        x = self.conv(x)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(x, x.size()[2])\n",
    "        #print(x.shape)\n",
    "        x = x.squeeze(2)\n",
    "        x = self.fc(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = Variable(torch.LongTensor(np.random.randint(0,50,size=(32,10))))\\n#50 is vocab size, 64 is embedding size\\ncnn = CNN(50, 64)\\ncnn(x)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x = Variable(torch.LongTensor(np.random.randint(0,50,size=(32,10))))\n",
    "#50 is vocab size, 64 is embedding size\n",
    "cnn = CNN(50, 64)\n",
    "cnn(x)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, dropout=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x.shape) #[b, s, e]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        #print(x.shape) #[s, b, e]\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        #print(x.shape) #[s, b, h*2]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A `Highway layer <https://arxiv.org/abs/1505.00387>`_ does a gated combination of a linear\n",
    "    transformation and a non-linear transformation of its input.  :math:`y = g * x + (1 - g) *\n",
    "    f(A(x))`, where :math:`A` is a linear transformation, :math:`f` is an element-wise\n",
    "    non-linearity, and :math:`g` is an element-wise gate, computed as :math:`sigmoid(B(x))`.\n",
    "    This module will apply a fixed number of highway layers to its input, returning the final\n",
    "    result.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim : ``int``\n",
    "        The dimensionality of :math:`x`.  We assume the input has shape ``(batch_size,\n",
    "        input_dim)``.\n",
    "    num_layers : ``int``, optional (default=``1``)\n",
    "        The number of highway layers to apply to the input.\n",
    "    activation : ``Callable[[torch.Tensor], torch.Tensor]``, optional (default=``torch.nn.functional.relu``)\n",
    "        The non-linearity to use in the highway layers.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 num_layers,\n",
    "                 activation = torch.nn.functional.relu):\n",
    "        super(Highway, self).__init__()\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._layers = torch.nn.ModuleList([torch.nn.Linear(embedding_dim, embedding_dim * 2)\n",
    "                                            for _ in range(num_layers)])\n",
    "        self._activation = activation\n",
    "                \n",
    "        for layer in self._layers:\n",
    "            # We should bias the highway layer to just carry its input forward.  We do that by\n",
    "            # setting the bias on `B(x)` to be positive, because that means `g` will be biased to\n",
    "            # be high, to we will carry the input forward.  The bias on `B(x)` is the second half\n",
    "            # of the bias vector in each Linear layer.\n",
    "            layer.bias[embedding_dim:].data.fill_(1)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ\n",
    "        current_input = inputs\n",
    "        for layer in self._layers:\n",
    "            projected_input = layer(current_input)\n",
    "            linear_part = current_input\n",
    "            # NOTE: if you modify this, think about whether you should modify the initialization\n",
    "            # above, too.\n",
    "            nonlinear_part = projected_input[:, (0 * self._embedding_dim):(1 * self._embedding_dim)]\n",
    "            gate = projected_input[:, (1 * self._embedding_dim):(2 * self._embedding_dim)]\n",
    "            nonlinear_part = self._activation(nonlinear_part)\n",
    "            gate = torch.nn.functional.sigmoid(gate)\n",
    "            current_input = gate * linear_part + (1 - gate) * nonlinear_part\n",
    "        return current_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"\n",
    "    NEED ONE FOR CHARS AND ONE FOR WORDS\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO THIS ONLY WORKS 1 WAY, EITHER MAKE BIDIRECTIONAL ORRRRRRR HAVE AN INPUT WITH THE WORDS REVERSED\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.LongTensor(np.random.randint(0,50,size=(32))))\n",
    "#50 is vocab size, 64 is embedding size\n",
    "\"\"\"\n",
    "TODO THIS ONLY WORKS 1 WAY, EITHER MAKE BIDIRECTIONAL ORRRRRRR HAVE AN INPUT WITH THE WORDS REVERSED\n",
    "\"\"\"\n",
    "\n",
    "#highway = Highway(50, 200, 2)\n",
    "#highway(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word.shape torch.Size([32, 250, 100])\n",
      "char.shape torch.Size([32, 10, 16])\n",
      "char_cnned.shape torch.Size([32, 100])\n",
      "c_cnn_embedded_char after expand torch.Size([32, 250, 100])\n",
      "highway_input.shape torch.Size([32, 250, 200])\n",
      "highway_input.shape (single) torch.Size([32, 200])\n",
      "embedded.shape torch.Size([32, 200])\n",
      "embedded.shape after expand torch.Size([32, 250, 200])\n",
      "c_embedded_phrase.shape torch.Size([250, 32, 200])\n",
      "q_embedded_phrase.shape torch.Size([15, 32, 200])\n"
     ]
    }
   ],
   "source": [
    "word_embedding_dim = 100\n",
    "char_embedding_dim = 16\n",
    "n_words = 1000 #vocab size, not length\n",
    "n_chars = 256 #vocab size, not length\n",
    "batch_size = 32\n",
    "context_max_word_len = 250 #max words in context\n",
    "context_max_char_len = 10 #max characters per word\n",
    "query_max_word_len = 15 #max words in context\n",
    "query_max_char_len = 10 #max characters per word SHOULD BE THE SAME AS CONTEXT_MAX_CHAR_LEN\n",
    "\n",
    "context_words = Variable(torch.LongTensor(np.random.randint(0,n_words,size=(batch_size,context_max_word_len))))\n",
    "context_chars = Variable(torch.LongTensor(np.random.randint(0,n_chars,size=(batch_size,context_max_char_len))))\n",
    "\n",
    "query_words = Variable(torch.LongTensor(np.random.randint(0,n_words,size=(batch_size,query_max_word_len))))\n",
    "query_chars = Variable(torch.LongTensor(np.random.randint(0,n_chars,size=(batch_size,query_max_char_len))))\n",
    "\n",
    "\"\"\"\n",
    "BEGIN CONTEXT TO ATTENTION FLOW LAYER INPUTS\n",
    "x_T to h_T\n",
    "\"\"\"\n",
    "\n",
    "word_embedding = Embedding(n_words, word_embedding_dim) #instantiate word -> vectors module\n",
    "char_embedding = Embedding(n_chars, char_embedding_dim) #instantiatet char -> vectors module\n",
    "\n",
    "c_embedded_word = word_embedding(context_words) #input words, get out vectors\n",
    "c_embedded_char = char_embedding(context_chars) #input char, get out vector\n",
    "\n",
    "char_cnn = CNN(n_chars, char_embedding_dim) #instantiate chars -> vector\n",
    "\n",
    "c_cnn_embedded_char = char_cnn(c_embedded_char) #input chars (of single word), get out vector\n",
    "\n",
    "#this is cnn \"encoded\" of a single word, need to do a loop to get a 32,100 for every word\n",
    "#every word needs to be broken down into characters\n",
    "#need to loop over the char_cnned = char_cnn(chars) line\n",
    "\n",
    "print('word.shape',c_embedded_word.shape)\n",
    "print('char.shape',c_embedded_char.shape)\n",
    "print('char_cnned.shape',c_cnn_embedded_char.shape) \n",
    " \n",
    "#for now, use this to pretend we have one char_cnned per word\n",
    "c_cnn_embedded_chars = c_cnn_embedded_char.unsqueeze(1).expand(batch_size, context_max_word_len, word_embedding_dim) \n",
    "  \n",
    "print('c_cnn_embedded_char after expand', c_cnn_embedded_chars.shape) \n",
    "    \n",
    "assert c_embedded_word.shape == c_cnn_embedded_chars.shape\n",
    "\n",
    "#MUST BE THE SAME BEFORE GOING THROUGH HIGHWAY LAYER\n",
    "\n",
    "highway = Highway(word_embedding_dim*2, num_layers=2) #instantiate word_emb + char_emb (from CNN)\n",
    "\n",
    "c_highway_input = torch.cat((c_cnn_embedded_chars, c_embedded_word), dim=2)\n",
    "\n",
    "print('highway_input.shape',c_highway_input.shape)\n",
    "\n",
    "print('highway_input.shape (single)',c_highway_input[:,0,:].shape)\n",
    "\n",
    "c_embedded = highway(c_highway_input[:,0,:])\n",
    "\n",
    "print('embedded.shape',c_embedded.shape) \n",
    "\n",
    "#this is output for one word + char combination, need to do for all, but for now lets expand!\n",
    "\n",
    "c_embeddeds = c_embedded.unsqueeze(1).expand(batch_size, context_max_word_len, word_embedding_dim*2)\n",
    "\n",
    "print('embedded.shape after expand', c_embeddeds.shape)\n",
    "\n",
    "phrase_layer = LSTM(word_embedding_dim*2, word_embedding_dim)\n",
    "\n",
    "c_embedded_phrase = phrase_layer(c_embeddeds)\n",
    "\n",
    "print('c_embedded_phrase.shape',c_embedded_phrase.shape)\n",
    "\n",
    "\"\"\"\n",
    "BEGIN QUERY TO ATTENTION FLOW LAYER INPUTS\n",
    "q_J to u_J\n",
    "\"\"\"\n",
    "\n",
    "q_embedded_word = word_embedding(query_words) #input words, get out vectors\n",
    "q_embedded_char = char_embedding(query_chars) #input char, get out vector\n",
    "\n",
    "q_cnn_embedded_char = char_cnn(q_embedded_char) #input chars (of single word), get out vector\n",
    "\n",
    "#HACK FOR NOW\n",
    "q_cnn_embedded_chars = q_cnn_embedded_char.unsqueeze(1).expand(batch_size, query_max_word_len, word_embedding_dim) \n",
    "\n",
    "q_highway_input = torch.cat((q_cnn_embedded_chars, q_embedded_word), dim=2)\n",
    "\n",
    "q_embedded = highway(q_highway_input[:,0,:])\n",
    "\n",
    "#HACK FOR NOW\n",
    "q_embeddeds = q_embedded.unsqueeze(1).expand(batch_size, query_max_word_len, word_embedding_dim*2)\n",
    "\n",
    "q_embedded_phrase = phrase_layer(q_embeddeds)\n",
    "\n",
    "print('q_embedded_phrase.shape',q_embedded_phrase.shape)\n",
    "\n",
    "#https://github.com/allenai/allennlp/blob/master/allennlp/modules/similarity_functions/linear.py\n",
    "#https://github.com/allenai/allennlp/blob/master/allennlp/modules/matrix_attention.py\n",
    "#allennlp/training_config/bidaf.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDAF(nn.Module):\n",
    "    def __init__(self, \n",
    "                 char_cnn_model_c, \n",
    "                 word_lstm_model_c, \n",
    "                 char_cnn_model_q, \n",
    "                 word_lstm_model_q, \n",
    "                 phrase_lstm_model, \n",
    "                 modeling_lstm_model):\n",
    "        \n",
    "        super(BiDAF, self).__init__()\n",
    "            \n",
    "        self.char_cnn_model_c =  \n",
    "        self.word_lstm_model_c =\n",
    "        self.char_cnn_model_q = \n",
    "        self.word_lstm_model_q = \n",
    "        self.phrase_lstm_model = \n",
    "        self.modeling_lstm_model =\n",
    "        \n",
    "        self.start_span = nn.Linear(whatever, max_len)\n",
    "        self.end_span = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cnn_model_c = CNN(1)\n",
    "word_lstm_model_c = LSTM(1)\n",
    "char_cnn_model_q = CNN(1)\n",
    "word_lstm_model_q = LSTM(1)\n",
    "phrase_lstm_model = LSTM(1)\n",
    "modeling_lstm_model = LSTM(1)\n",
    "\n",
    "bidaf = BiDAF(char_cnn_model, word_lstm_model, phrase_lstm_model, modeling_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.LongTensor(np.random.randint(0,50,size=(32,100)))\n",
    "query = torch.LongTensor(np.random.randint(0,50,size=(32,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
